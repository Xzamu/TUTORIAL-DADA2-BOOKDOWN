[["introducción-a-dada2.html", "Análisis 16s rRNA utilizando DADA2 Capítulo 1 Introducción a DADA2 1.1 Instalación de DADA2 en R (versión 4.3) 1.2 Configuramos el directorio en el que se ubican las reads 1.3 Ordenamos los archivos y extraemos el nombre de las muestras 1.4 Establecer ruta para archivos filtrados 1.5 Filtrar y recortar lecturas 1.6 Estimación de la tasa de error 1.7 Dereplicar lecturas 1.8 Inferencia de secuencias 1.9 Fusionar lecturas emparejadas 1.10 Crear tabla de secuencias 1.11 Eliminar quimeras 1.12 Asignar taxonomía 1.13 Impresión de resultados 1.14 Alinear secuencias 1.15 Crear matriz de distancia 1.16 Realizar Neighbor Joining 1.17 Actualizamos el modelo con nuevos parámetros 1.18 Optimizamos el modelo GTR con parámetros de inversión y tasa de gamma 1.19 Desacoplamos el paquete phangorn para evitar conflictos 1.20 Leemos los metadatos de las muestras desde un archivo CSV 1.21 Verificamos que los nombres de las filas de la tabla de secuencias coincidan con los metadatos 1.22 Construimos un objeto phyloseq con la tabla de OTU, los metadatos de las muestras, la tabla taxonómica y el árbol filogenético 1.23 Eliminamos las muestras sintéticas del objeto phyloseq 1.24 Imprimimos el objeto phyloseq resultante 1.25 Estrategias de análsis 1.26 Cross-references 1.27 Chapters and sub-chapters 1.28 Captioned figures and tables", " Análisis 16s rRNA utilizando DADA2 Tu nombre 2023-11-06 Capítulo 1 Introducción a DADA2 Repositorio de GitHub aquí Cita: Callahan, B. J., McMurdie, P. J., Rosen, M. J., Han, A. W., Johnson, A. J. A., y Holmes, S. P. (2016). DADA2: High-resolution sample inference from Illumina amplicon data. Nature methods, 13(7), 581-583. Descripción: DADA2 es un paquete de software de código abierto utilizado para modelar y corregir errores en secuencias de amplicones secuenciados con el protocolo Illumina. Infiere secuencias de una muestra de manera exacta y resuelve diferencias con una resolución de un nucleótido. Los datos utilizados pueden ser consultados en el European Nucleotide Archive (ENA) bajo el nombre de proyecto PRJNA428495. Descargamos los archivos FASTQ en la sección “Generated FASTQ files: FTP” y los guardamos en una carpeta. Los binarios del paquete DADA2 están disponibles a través de Bioconductor 1.1 Instalación de DADA2 en R (versión 4.3) Este bloque instala el paquete DADA2 a través de Bioconductor. Es importante tener instalado BiocManager para poder acceder a los paquetes de Bioconductor. if (!require(&quot;BiocManager&quot;, quietly = TRUE)) install.packages(&quot;BiocManager&quot;) BiocManager::install(&quot;dada2&quot;) library(dada2) 1.2 Configuramos el directorio en el que se ubican las reads path &lt;- &quot;/Users/&quot; # Cambiamos al directorio que contiene las reads list.files(path) 1.3 Ordenamos los archivos y extraemos el nombre de las muestras Este bloque ordena los archivos FASTQ y extrae el nombre de las muestras. Asegúrate de que los patrones de búsqueda (pattern=“_1.fastq.gz” y pattern=“_2.fastq.gz”) coincidan con la nomenclatura de tus archivos. fnFs &lt;- sort(list.files(path, pattern=&quot;_1.fastq.gz&quot;)) fnRs &lt;- sort(list.files(path, pattern=&quot;_2.fastq.gz&quot;)) sample.names &lt;- sapply(strsplit(fnFs, &quot;_&quot;), &#39;[&#39;, 1) fnFs &lt;- file.path(path, fnFs) fnRs &lt;- file.path(path, fnRs) 1.4 Establecer ruta para archivos filtrados Define una ruta basada en la variable sample.names donde guardar los archivos filtrados. El código genera nombres de archivo con un sufijo (“_F_filt.fastq.gz” o “_R_filt.fastq.gz”) para diferenciarlos. filt_path &lt;- file.path(path, &quot;filtered&quot;) filtFs &lt;- file.path(filt_path, paste0(sample.names, &quot;_F_filt.fastq.gz&quot;)) filtRs &lt;- file.path(filt_path, paste0(sample.names, &quot;_R_filt.fastq.gz&quot;)) print(fnFs) print(fnRs) print(filtFs) print(filtRs) 1.5 Filtrar y recortar lecturas La función filterAndTrim se utiliza para el filtrado y recorte de las lecturas, es decir, se eliminan las lecturas de baja calidad y las recorta a una longitud específica. Se especifican varios parámetros, como las longitudes de truncamiento, la calidad máxima permitida, la eliminación de secuencias de fagos (rm.phix), la compresión y el uso de múltiples hilos (multithread). El resultado se almacena en la variable out. Windows 10 permite el ‘multi-theading’, excepto en el comando filterAndTrim. out &lt;- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(250, 200), maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE, compress=TRUE, multithread=TRUE) 1.6 Estimación de la tasa de error Se estima la tasa de error para las lecturas adelante (errF) y las lecturas reversas (errR) utilizando la función learnErrors. La opción multithread=TRUE se utiliza para acelerar el proceso. errF &lt;- learnErrors(filtFs, multithread=TRUE) errR &lt;- learnErrors(filtRs, multithread=TRUE) 1.7 Dereplicar lecturas Se realiza la eliminación de duplicados de lecturas (dereplicación) para las lecturas adelante (derepFs) y las lecturas reversas (derepRs) utilizando la función derepFastq. Se asignan nombres a las muestras con sample.names. derepFs &lt;- derepFastq(filtFs, verbose=TRUE) derepRs &lt;- derepFastq(filtRs, verbose=TRUE) names(derepFs) &lt;- sample.names names(derepRs) &lt;- sample.names 1.8 Inferencia de secuencias Se utilizan las tasas de error estimadas en el paso anterior para la inferencia de secuencias únicas utilizando la función dada para las lecturas adelante (dadaFs) y las lecturas reversas (dadaRs). dadaRs &lt;- dada(derepRs, err=errR, multithread=TRUE) dadaFs &lt;- dada(derepFs, err=errF, multithread=TRUE) 1.9 Fusionar lecturas emparejadas Aquí se fusiona las secuencias emparejadas utilizando la función mergePairs. Las secuencias únicas y las lecturas originales se utilizan para la fusión, y los resultados se almacenan en la variable mergers. mergers &lt;- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=TRUE) 1.10 Crear tabla de secuencias Se crea una tabla de secuencias utilizando la función makeSequenceTable. Esta tabla contendrá información sobre las secuencias y su abundancia. seqtab &lt;- makeSequenceTable(mergers) 1.11 Eliminar quimeras Las quimeras son secuencias que resultan de la combinación de dos o más secuencias parentales diferentes durante el proceso de amplificación por PCR. Estas formaciones ocurren en ciclos posteriores de PCR cuando hay una alta concentración de cebadores parcialmente extendidos que compiten con los cebadores originales. Se realiza la eliminación de quimeras utilizando la función removeBimeraDenovo. Se especifica el método de eliminación como “consensus”. seqtab.nochim &lt;- removeBimeraDenovo(seqtab, method=&quot;consensus&quot;, multithread=TRUE, verbose=TRUE) Las quimeras puede introducir artefactos¿¿‘¿’¿ en los análisis de datos, dando lugar a interpretaciones erróneas. En el análisis de datos usando DADA2, las quimeras se eliminan utilizando el código removeBimeraDenovo. Esta función es una interfaz de conveniencia para la eliminación de quimeras. DADA2 ofrece varios métodos para identificar quimeras, como la identificación a partir de secuencias agrupadas y la identificación por consenso entre muestras. Al utilizar el método de consenso, por ejemplo, las muestras en una tabla de secuencias se verifican independientemente en busca de quimeras, y se toma una decisión de consenso sobre cada variante de secuencia. DADA2 es muy meticuloso al tratar con estas quimeras para asegurar que los datos analizados sean precisos. Por ejemplo, al utilizar removeBimeraDenovo con el método “pooled”, todas las muestras en la tabla de secuencias se agrupan para la identificación de quimeras. Si se usa el método “consensus”, las muestras en una tabla de secuencias se verifican independientemente en busca de quimeras, y se toma una decisión de consenso sobre cada variante de secuencia. Esto es vital ya que las quimeras pueden variar entre las muestras y es esencial asegurarse de que no afecten los resultados. En conclusión, eliminar quimeras o bimeras es esencial para obtener una representación precisa de las comunidades microbianas en los análisis de datos. Si no se eliminan, podrían llevar a interpretaciones erróneas de la estructura y diversidad de la comunidad. DADA2 proporciona herramientas efectivas para identificar y eliminar estas quimeras, asegurando así la calidad y precisión de los resultados obtenidos. 1.12 Asignar taxonomía Se asigna la taxonomía a las secuencias utilizando la función assignTaxonomy. Se proporciona un archivo de referencia para la asignación taxonómica, y se utiliza el multithread para acelerar el proceso. La base de datos taxonómica utilizada será un archivo fasta de entrenamiento derivado de la versión 138.1 del Proyecto Silva y formateado para su uso con DADA2. Este archivo puede ser descargado de Zenodo. taxa &lt;- assignTaxonomy(seqtab.nochim, &quot;C:/Users/UBBBC/Desktop/Samuel/PRJNA428495/silva_nr99_v138.1_train_set.fa.gz&quot;, multithread=TRUE) 1.13 Impresión de resultados Se imprime en la consola las primeras filas de la asignación taxonómica resultante. unname(head(taxa)) 1.14 Alinear secuencias ‘getSequences’ extrae las secuencias de la tabla sin quimeras. ‘names(sequences)’ asigna a cada secuencia su propio nombre para su fácil identificación. sequences &lt;- getSequences(seqtab.nochim) names(sequences) &lt;- sequences ‘AlignSeqs’ de la biblioteca ‘DECIPHER’ alinea las secuencias de ADN. ‘DNAStringSet’ convierte las secuencias en un formato adecuado para el alineamiento. ‘anchor=NA’ indica que no se usará un anclaje durante el alineamiento. alignment &lt;- AlignSeqs(DNAStringSet(sequences), anchor=NA) 1.15 Crear matriz de distancia ‘phyDat’ convierte las alineaciones en un formato que puede ser utilizado por funciones de filogenética. ‘type=“DNA”’ especifica que los datos son secuencias de ADN. ‘dist.ml’ calcula una matriz de distancias utilizando el método de máxima verosimilitud. phang.align &lt;- phyDat(as(alignment, &quot;matrix&quot;), type=&quot;DNA&quot;) dm &lt;- dist.ml(phang.align) 1.16 Realizar Neighbor Joining ‘NJ’ realiza un análisis filogenético utilizando el método Neighbor Joining. La salida es un árbol filogenético basado en la matriz de distancias. treeNJ &lt;- NJ(dm) # NJ es Neighbor Joining fit &lt;- pml(treeNJ, data=phang.align) ‘pml’ (de la biblioteca phangorn) ajusta un modelo de máxima verosimilitud al árbol filogenético. ‘treeNJ’ es el árbol generado por Neighbor Joining. ‘data=phang.align’ son los datos de alineación convertidos previamente con ‘phyDat’. 1.17 Actualizamos el modelo con nuevos parámetros fitGTR &lt;- update(fit, k=4, inv=0.2) update: Actualiza un modelo previamente ajustado (fit) con nuevos parámetros. k=4: Define el número de categorías de tasa para el modelo gamma de tasas de sustitución de nucleótidos variables entre sitios. inv=0.2: Establece la proporción de sitios invariables en 0.2. “JUSTIFICACIÓN” 1.18 Optimizamos el modelo GTR con parámetros de inversión y tasa de gamma fitGTR &lt;- optim.pml(fitGTR, model=&quot;GTR&quot;, optInv=TRUE, optGamma=TRUE, rearrangement = &quot;stochastic&quot;, control = pml.control(trace = 0)) optim.pml1 1.19 Desacoplamos el paquete phangorn para evitar conflictos detach(&quot;package:phangorn&quot;, unload=TRUE) 1.20 Leemos los metadatos de las muestras desde un archivo CSV samdf &lt;- read.csv(&quot;metadata.csv&quot;, header=TRUE, row.names = 1) 1.21 Verificamos que los nombres de las filas de la tabla de secuencias coincidan con los metadatos rownames(seqtabNoC) %in% rownames(samdf) all(rownames(seqtabAll) %in% samdf$run) 1.22 Construimos un objeto phyloseq con la tabla de OTU, los metadatos de las muestras, la tabla taxonómica y el árbol filogenético ps &lt;- phyloseq(otu_table(seqtabNoC, taxa_are_rows=FALSE), sample_data(samdf), tax_table(taxTab), phy_tree(fitGTR$tree)) Phyloseq . 1.23 Eliminamos las muestras sintéticas del objeto phyloseq ps &lt;- prune_samples(sample_names(ps) != &quot;Mock&quot;, ps) 1.24 Imprimimos el objeto phyloseq resultante ps #Buenas Prácticas 1.25 Estrategias de análsis 1.25.1 Comparación de “pipelines” Al comparar pipelines para el análisis de datos de secuenciación del gen 16S rRNA, se deben considerar factores como la facilidad de uso, la documentación disponible y el tiempo de análisis. Pipelines populares como QIIME, MG-RAST, UPARSE y mothur ofrecen herramientas completas desde el control de calidad hasta el agrupamiento OTUs. Sin embargo, la accesibilidad para usuarios con conocimientos computacionales limitados y la calidad de la documentación varían entre estos paquetes. Estudios han mostrado que aunque herramientas como mothur y QIIME tienen documentación extensa que puede ser ventajosa, el tiempo de análisis y la facilidad de uso difieren significativamente entre los paquetes, con QIIME siendo rápido (aproximadamente 1 hora) y MG-RAST más lento (aproximadamente 2 días) pero adecuado para usuarios sin experiencia en línea de comandos. La elección del pipeline dependerá del nivel de experiencia del usuario y de los recursos disponibles en su institución. 1.26 Cross-references Cross-references make it easier for your readers to find and link to elements in your book. 1.27 Chapters and sub-chapters There are two steps to cross-reference any heading: Label the heading: # Hello world {#nice-label}. Leave the label off if you like the automated heading generated based on your heading title: for example, # Hello world = # Hello world {#hello-world}. To label an un-numbered heading, use: # Hello world {-#nice-label} or {# Hello world .unnumbered}. Next, reference the labeled heading anywhere in the text using \\@ref(nice-label); for example, please see Chapter 1.26. If you prefer text as the link instead of a numbered reference use: any text you want can go here. 1.28 Captioned figures and tables Figures and tables with captions can also be cross-referenced from elsewhere in your book using \\@ref(fig:chunk-label) and \\@ref(tab:chunk-label), respectively. See Figure 1.1. par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figure 1.1: Here is a nice figure! Don’t miss Table 1.1. knitr::kable( head(pressure, 10), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 1.1: Here is a nice table! temperature pressure 0 0.0002 20 0.0012 40 0.0060 60 0.0300 80 0.0900 100 0.2700 120 0.7500 140 1.8500 160 4.2000 180 8.8000 La geocomputación ha evolucionado significativamente en las últimas décadas Optimiza un modelo filogenético basado en máxima verosimilitud.↩︎ "],["parts.html", "Capítulo 2 Parts", " Capítulo 2 Parts You can add parts to organize one or more book chapters together. Parts can be inserted at the top of an .Rmd file, before the first-level chapter heading in that same file. Add a numbered part: # (PART) Act one {-} (followed by # A chapter) Add an unnumbered part: # (PART\\*) Act one {-} (followed by # A chapter) Add an appendix as a special kind of un-numbered part: # (APPENDIX) Other stuff {-} (followed by # A chapter). Chapters in an appendix are prepended with letters instead of numbers. "],["footnotes-and-citations.html", "Capítulo 3 Footnotes and citations 3.1 Footnotes 3.2 Citations", " Capítulo 3 Footnotes and citations 3.1 Footnotes Footnotes are put inside the square brackets after a caret ^[]. Like this one 2. 3.2 Citations Reference items in your bibliography file(s) using @key. For example, we are using the bookdown package [@R-bookdown] (check out the last code chunk in index.Rmd to see how this citation key was added) in this sample book, which was built on top of R Markdown and knitr [@xie2015] (this citation was added manually in an external file book.bib). Note that the .bib files need to be listed in the index.Rmd with the YAML bibliography key. The RStudio Visual Markdown Editor can also make it easier to insert citations: https://rstudio.github.io/visual-markdown-editing/#/citations This is a footnote.↩︎ "],["blocks.html", "Capítulo 4 Blocks 4.1 Equations 4.2 Theorems and proofs 4.3 Callout blocks", " Capítulo 4 Blocks 4.1 Equations Here is an equation. \\[\\begin{equation} f\\left(k\\right) = \\binom{n}{k} p^k\\left(1-p\\right)^{n-k} \\tag{4.1} \\end{equation}\\] You may refer to using \\@ref(eq:binom), like see Equation (4.1). 4.2 Theorems and proofs Labeled theorems can be referenced in text using \\@ref(thm:tri), for example, check out this smart theorem 4.1. Theorem 4.1 For a right triangle, if \\(c\\) denotes the length of the hypotenuse and \\(a\\) and \\(b\\) denote the lengths of the other two sides, we have \\[a^2 + b^2 = c^2\\] Read more here https://bookdown.org/yihui/bookdown/markdown-extensions-by-bookdown.html. 4.3 Callout blocks The R Markdown Cookbook provides more help on how to use custom blocks to design your own callouts: https://bookdown.org/yihui/rmarkdown-cookbook/custom-blocks.html "],["sharing-your-book.html", "Capítulo 5 Sharing your book 5.1 Publishing 5.2 404 pages 5.3 Metadata for sharing", " Capítulo 5 Sharing your book 5.1 Publishing HTML books can be published online, see: https://bookdown.org/yihui/bookdown/publishing.html 5.2 404 pages By default, users will be directed to a 404 page if they try to access a webpage that cannot be found. If you’d like to customize your 404 page instead of using the default, you may add either a _404.Rmd or _404.md file to your project root and use code and/or Markdown syntax. 5.3 Metadata for sharing Bookdown HTML books will provide HTML metadata for social sharing on platforms like Twitter, Facebook, and LinkedIn, using information you provide in the index.Rmd YAML. To setup, set the url for your book and the path to your cover-image file. Your book’s title and description are also used. This gitbook uses the same social sharing data across all chapters in your book- all links shared will look the same. Specify your book’s source repository on GitHub using the edit key under the configuration options in the _output.yml file, which allows users to suggest an edit by linking to a chapter’s source file. Read more about the features of this output format here: https://pkgs.rstudio.com/bookdown/reference/gitbook.html Or use: ?bookdown::gitbook "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
